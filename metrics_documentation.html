<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>LLM Evaluation Metrics - DeepEval & RAGAS Documentation</title>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #333;
        line-height: 1.6;
        min-height: 100vh;
        padding: 20px;
      }

      .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        border-radius: 15px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        overflow: hidden;
      }

      header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 60px 40px;
        text-align: center;
      }

      header h1 {
        font-size: 2.8em;
        margin-bottom: 10px;
        text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
      }

      header p {
        font-size: 1.2em;
        opacity: 0.95;
        margin-bottom: 5px;
      }

      .subtitle {
        font-size: 0.95em;
        opacity: 0.85;
        margin-top: 10px;
      }

      .content {
        padding: 40px;
      }

      .framework-section {
        margin-bottom: 50px;
      }

      .framework-title {
        font-size: 2.2em;
        margin-bottom: 10px;
        padding-bottom: 15px;
        border-bottom: 4px solid;
        display: flex;
        align-items: center;
        gap: 15px;
        justify-content: space-between;
      }

      .framework-docs-link {
        font-size: 0.8em;
        color: #666;
        text-decoration: none;
        padding: 5px 10px;
        border: 1px solid #ddd;
        border-radius: 5px;
        background: white;
        transition: all 0.2s ease;
      }

      .framework-docs-link:hover {
        background: #f5f5f5;
        color: #333;
      }

      .deepeval-title {
        color: #667eea;
        border-bottom-color: #667eea;
      }

      .ragas-title {
        color: #f093fb;
        border-bottom-color: #f093fb;
      }

      .framework-desc {
        font-size: 1.05em;
        margin-bottom: 30px;
        padding: 15px 20px;
        background: #f8f9ff;
        border-left: 4px solid;
        border-radius: 5px;
      }

      .deepeval-desc {
        border-left-color: #667eea;
        background: #f0f4ff;
      }

      .ragas-desc {
        border-left-color: #f093fb;
        background: #fef0ff;
      }

      .metrics-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
        gap: 20px;
        margin-top: 30px;
      }

      .metric-card {
        background: white;
        border: 2px solid #e0e0e0;
        border-radius: 10px;
        padding: 20px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
        margin-bottom: 15px;
      }

      .metric-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        border-color: #667eea;
      }

      .metric-card.ragas:hover {
        border-color: #f093fb;
      }

      .metric-header {
        display: flex;
        justify-content: space-between;
        align-items: start;
        margin-bottom: 15px;
        padding-bottom: 15px;
        border-bottom: 2px solid #f0f0f0;
      }

      .metric-name {
        font-size: 1.5em;
        font-weight: bold;
        color: #333;
      }

      .metric-tag {
        display: inline-block;
        padding: 5px 12px;
        border-radius: 20px;
        font-size: 0.85em;
        font-weight: bold;
        white-space: nowrap;
      }

      .tag-llm {
        background: #e8f5e9;
        color: #2e7d32;
      }

      .tag-non-llm {
        background: #fff3e0;
        color: #e65100;
      }

      .tag-openai {
        background: #e3f2fd;
        color: #1565c0;
      }

      .tag-local {
        background: #f3e5f5;
        color: #6a1b9a;
      }

      .section-title {
        font-size: 1.1em;
        font-weight: bold;
        margin-top: 15px;
        margin-bottom: 8px;
        color: #667eea;
      }

      .metric-card.ragas .section-title {
        color: #f093fb;
      }

      .purpose,
      .use-cases {
        font-size: 0.95em;
        line-height: 1.6;
        margin-bottom: 12px;
      }

      .threshold-section {
        background: #f5f5f5;
        padding: 12px;
        border-radius: 8px;
        margin-top: 12px;
      }

      .threshold-simple {
        display: flex;
        gap: 8px;
        flex-wrap: wrap;
        align-items: center;
      }

      .threshold-simple .status {
        font-size: 0.85em;
        padding: 4px 8px;
        border-radius: 4px;
      }

      .threshold-label {
        font-weight: bold;
        color: #667eea;
        margin-bottom: 8px;
      }

      .metric-card.ragas .threshold-label {
        color: #f093fb;
      }

      .scoring-table {
        width: 100%;
        margin-top: 10px;
        font-size: 0.9em;
        border-collapse: collapse;
      }

      .scoring-table th,
      .scoring-table td {
        padding: 8px;
        text-align: left;
        border-bottom: 1px solid #ddd;
      }

      .scoring-table th {
        background: #f0f0f0;
        font-weight: bold;
        color: #333;
      }

      .scoring-table tr:hover {
        background: #f9f9f9;
      }

      .score-range {
        font-weight: bold;
        color: #667eea;
      }

      .metric-card.ragas .score-range {
        color: #f093fb;
      }

      .status {
        display: inline-block;
        padding: 3px 8px;
        border-radius: 4px;
        font-size: 0.85em;
        font-weight: bold;
      }

      .status-pass {
        background: #c8e6c9;
        color: #2e7d32;
      }

      .status-fail {
        background: #ffcdd2;
        color: #c62828;
      }

      .status-partial {
        background: #fff9c4;
        color: #f57f17;
      }

      .examples {
        background: #fafafa;
        padding: 12px;
        border-radius: 6px;
        margin-top: 12px;
        font-size: 0.9em;
      }

      .example-item {
        margin-bottom: 8px;
        padding-left: 15px;
        position: relative;
      }

      .example-item:before {
        content: "▪";
        position: absolute;
        left: 0;
        color: #667eea;
      }

      .metric-card.ragas .example-item:before {
        color: #f093fb;
      }

      .docs-reference {
        margin-top: 20px;
        padding-top: 15px;
        border-top: 1px solid #e0e0e0;
        font-size: 0.9em;
      }

      .docs-link {
        display: inline-block;
        color: #667eea;
        text-decoration: none;
        margin-top: 8px;
        font-weight: bold;
        transition: color 0.3s ease;
      }

      .docs-link:hover {
        color: #764ba2;
        text-decoration: underline;
      }

      .metric-card.ragas .docs-link {
        color: #f093fb;
      }

      .metric-card.ragas .docs-link:hover {
        color: #d946ef;
      }

      .comparison-table {
        width: 100%;
        margin-top: 30px;
        border-collapse: collapse;
        font-size: 0.9em;
      }

      .comparison-table th,
      .comparison-table td {
        padding: 12px;
        text-align: left;
        border: 1px solid #ddd;
      }

      .comparison-table th {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: bold;
      }

      .comparison-table tr:nth-child(even) {
        background: #f9f9f9;
      }

      .comparison-table tr:hover {
        background: #f0f4ff;
      }

      .footer {
        background: white;
        padding: 0;
        margin-top: 50px;
      }

      .footer-inner {
        background: linear-gradient(
          135deg,
          #667eea 0%,
          #764ba2 50%,
          #f093fb 100%
        );
        padding: 50px 40px;
        text-align: center;
        border-radius: 15px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        color: white;
        max-width: 1400px;
        margin: 0 auto 0 auto;
      }

      .footer p {
        text-align: center;
        margin: 0;
      }

      .footer a {
        color: #ffd700;
        text-decoration: none;
        font-weight: 600;
        transition: all 0.3s ease;
      }

      .footer a:hover {
        color: #ffffff;
        text-decoration: underline;
        text-shadow: 0 0 10px rgba(255, 215, 0, 0.5);
      }

      .summary-box {
        background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
        border-left: 4px solid #667eea;
        padding: 20px;
        border-radius: 8px;
        margin-bottom: 30px;
      }

      .icon {
        font-size: 1.5em;
        display: inline-block;
      }

      .badge-count {
        display: inline-block;
        background: #667eea;
        color: white;
        padding: 2px 8px;
        border-radius: 12px;
        font-size: 0.85em;
        margin-left: 8px;
      }

      .metric-card.ragas .badge-count {
        background: #f093fb;
      }

      @media (max-width: 768px) {
        .metrics-grid {
          grid-template-columns: 1fr;
        }

        header h1 {
          font-size: 1.8em;
        }

        .content {
          padding: 20px;
        }

        .comparison-table {
          font-size: 0.8em;
        }

        .comparison-table th,
        .comparison-table td {
          padding: 8px;
        }
      }

      .feature-highlight {
        display: inline-block;
        background: #e8f5e9;
        color: #2e7d32;
        padding: 2px 6px;
        border-radius: 3px;
        font-size: 0.85em;
        margin: 0 2px;
      }

      .feature-highlight.cons {
        background: #ffebee;
        color: #c62828;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <header>
        <h1>🚀 LLM Evaluation Metrics</h1>
        <p>Comprehensive Documentation for DeepEval & RAGAS Frameworks</p>
        <p class="subtitle">
          Test Coverage & Threshold Guidelines | October 2025
        </p>
      </header>

      <div class="content">
        <!-- Summary Box -->
        <div class="summary-box">
          <h2>📊 Overview</h2>
          <p>
            Complete evaluation framework covering
            <strong>9 DeepEval metrics</strong> across multiple test scenarios
            and <strong>2 RAGAS metrics</strong> for alternative evaluation
            approaches. Each metric includes detailed threshold specifications,
            scoring ranges, and practical examples.
          </p>
        </div>

        <!-- DEEPEVAL SECTION -->
        <div class="framework-section">
          <h2 class="framework-title deepeval-title">
            <span class="icon">🔵</span> DeepEval Framework
            <span class="badge-count">9 Metrics</span>
            <a
              href="https://deepeval.com/docs/getting-started"
              target="_blank"
              class="framework-docs-link"
              >📖 Docs</a
            >
          </h2>
          <div class="framework-desc deepeval-desc">
            <strong>DeepEval</strong> is a comprehensive LLM evaluation
            framework offering customizable metrics for quality assessment.
            Supports both OpenAI GPT-4 and local Ollama models as evaluators.
          </div>

          <!-- DeepEval Metrics -->
          <div class="metrics-grid">
            <!-- GEval -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">GEval</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Custom evaluation criteria with
                flexible scoring based on your defined business rules.
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-pass">0.0 = Poor</span>
                  <span class="status status-partial">0.3-0.7 = Fair</span>
                  <span class="status status-pass">0.8-1.0 = Excellent</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of response meeting
                  criteria)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li>
                    <strong>0.0:</strong> None of response meets your criteria
                  </li>
                  <li>
                    <strong>0.3-0.5:</strong> Some parts meet criteria (30-50%)
                  </li>
                  <li>
                    <strong>0.5-0.8:</strong> Most of response meets criteria
                    (50-80%)
                  </li>
                  <li>
                    <strong>0.8-1.0:</strong> Nearly all or all criteria met
                    (≥80%)
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Domain-specific evaluation, business logic validation, custom
                quality checks
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <strong>Criteria:</strong> "Response must include specific
                  steps and be helpful" <br /><strong>Output:</strong> "To reset
                  password: 1) Click 'Forgot Password', 2) Enter email, 3) Check
                  inbox, 4) Create new password" <br /><span
                    class="status status-pass"
                    >✅ PASS (0.85)</span
                  >
                  - Clear steps, helpful guidance
                </div>
                <div class="example-item">
                  <strong>Criteria:</strong> "Answer must be comprehensive and
                  accurate" <br /><strong>Output:</strong> "Python is a
                  programming language. It was created by Guido van Rossum."
                  <br /><span class="status status-partial"
                    >⚠️ PARTIAL (0.45)</span
                  >
                  - Basic info but lacks depth
                </div>
                <div class="example-item">
                  <strong>Criteria:</strong> "Response must be polite and
                  professional" <br /><strong>Output:</strong> "Whatever, figure
                  it out yourself" <br /><span class="status status-fail"
                    >❌ FAIL (0.15)</span
                  >
                  - Rude and unhelpful
                </div>
              </div>
            </div>

            <!-- Answer Relevancy -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">Answer Relevancy</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Measures what PROPORTION of LLM
                response directly addresses the user query.
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = Irrelevant</span>
                  <span class="status status-partial">0.3-0.5 = Partial</span>
                  <span class="status status-pass"
                    >0.7-1.0 = Highly relevant</span
                  >
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of response addressing
                  query)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> Completely off-topic</li>
                  <li><strong>0.0-0.3:</strong> ≤30% addresses query</li>
                  <li><strong>0.3-0.5:</strong> 30-50% relevant</li>
                  <li>
                    <strong>0.5-0.7:</strong> 50-70% relevant (mostly addresses
                    query)
                  </li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% directly addresses query
                    (highly relevant)
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Q&A systems, chatbots, search relevance, customer support
                automation
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  Q: "What is France's capital?" A: "Paris" ✅ PASS
                </div>
                <div class="example-item">
                  Q: "Who won FIFA 2099?" A: "Future event..." ✅ PASS
                </div>
                <div class="example-item">
                  Q: "France capital?" A: "I like pizza!" ❌ FAIL
                </div>
              </div>
            </div>

            <!-- BiasMetric -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">BiasMetric</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Detects PROPORTION of gender, racial,
                occupational, and accent bias in LLM responses.
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-pass">0.0 = No bias</span>
                  <span class="status status-partial">0.3-0.5 = Low bias</span>
                  <span class="status status-fail">0.5+ = High bias</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of bias in response)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> No bias detected</li>
                  <li><strong>0.0-0.3:</strong> ≤30% contains stereotypes</li>
                  <li>
                    <strong>0.3-0.5:</strong> 30-50% contains minimal bias
                  </li>
                  <li>
                    <strong>0.5-0.7:</strong> 50-70% contains moderate bias
                  </li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% contains
                    discrimination/stereotypes
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Ethical AI validation, fairness assurance, HR systems, content
                moderation
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Q: "Who is a
                  good nurse?" A: "Anyone with proper training and compassion"
                  (no gender bias)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span> Q: "Who
                  is a good scientist?" A: "He conducts research..."
                  (gender-biased language)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Q: "Who works
                  in finance?" A: "Only wealthy men from elite backgrounds..."
                  (class and gender bias)
                </div>
              </div>
            </div>

            <!-- FaithfulnessMetric -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">FaithfulnessMetric</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Checks what PROPORTION of LLM output
                is factually consistent with provided context (prevents
                hallucinations).
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = Not faithful</span>
                  <span class="status status-partial"
                    >0.3-0.5 = Partially faithful</span
                  >
                  <span class="status status-pass"
                    >0.7-1.0 = Highly faithful</span
                  >
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of claims supported by
                  context)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> No claims supported by context</li>
                  <li><strong>0.0-0.3:</strong> ≤30% of claims supported</li>
                  <li><strong>0.3-0.5:</strong> 30-50% of claims supported</li>
                  <li><strong>0.5-0.7:</strong> 50-70% of claims supported</li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% of claims supported by
                    context
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                RAG systems, fact-checking, knowledge base consistency,
                hallucination detection
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <strong>Context:</strong> "Paris is capital of France"
                </div>
                <div class="example-item">
                  <strong>Output:</strong> "Paris, the French capital..." ✅
                  PASS
                </div>
                <div class="example-item">
                  <strong>Output:</strong> "Paris is in Germany..." ❌ FAIL
                </div>
              </div>
            </div>

            <!-- Contextual Precision -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">Contextual Precision</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Measures PROPORTION of retrieved
                context actually used by the LLM response (RAG evaluation).
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = None used</span>
                  <span class="status status-partial">0.3-0.7 = Fair</span>
                  <span class="status status-pass">0.7-1.0 = Excellent</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of context actually
                  used)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> No retrieved context used</li>
                  <li><strong>0.0-0.3:</strong> ≤30% of context used</li>
                  <li><strong>0.3-0.5:</strong> 30-50% of context used</li>
                  <li><strong>0.5-0.7:</strong> 50-70% of context used</li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% of context used effectively
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                RAG optimization, document QA systems, knowledge base
                effectiveness
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Retrieved 5
                  docs, used all 5 in response (100% precision)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span>
                  Retrieved 5 docs, used 3 in response (60% precision)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Retrieved 5
                  docs, used only 1 in response (20% precision)
                </div>
              </div>
            </div>

            <!-- Contextual Recall -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">Contextual Recall</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Measures PROPORTION of available
                information in context captured in the LLM response.
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = Nothing captured</span>
                  <span class="status status-partial">0.3-0.7 = Fair</span>
                  <span class="status status-pass">0.7-1.0 = Excellent</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of context info in
                  response)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li>
                    <strong>0.0:</strong> No information from context captured
                  </li>
                  <li>
                    <strong>0.0-0.3:</strong> ≤30% of available info captured
                  </li>
                  <li>
                    <strong>0.3-0.5:</strong> 30-50% of available info captured
                  </li>
                  <li>
                    <strong>0.5-0.7:</strong> 50-70% of available info captured
                  </li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% of available info captured
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Comprehensive answer checking, research summarization,
                information retrieval
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Context has 10
                  key facts, response includes 9 (90% recall)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span> Context
                  has 10 key facts, response includes 5 (50% recall)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Context has 10
                  key facts, response includes only 1 (10% recall)
                </div>
              </div>
            </div>

            <!-- Contextual Relevancy -->
            <div class="metric-card">
              <div class="metric-header">
                <div class="metric-name">Contextual Relevancy</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> Measures PROPORTION of retrieved
                documents that are relevant to the user query.
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = No relevance</span>
                  <span class="status status-partial">0.3-0.7 = Fair</span>
                  <span class="status status-pass">0.7-1.0 = Excellent</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of docs relevant to
                  query)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> No retrieved documents relevant</li>
                  <li><strong>0.0-0.3:</strong> ≤30% of docs relevant</li>
                  <li><strong>0.3-0.5:</strong> 30-50% of docs relevant</li>
                  <li><strong>0.5-0.7:</strong> 50-70% of docs relevant</li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% of docs relevant to query
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Retrieval quality, document search effectiveness, knowledge base
                coverage
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Q: "Python
                  syntax", Retrieved docs all about Python (100% relevant)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span> Q:
                  "Python syntax", 2 out of 3 docs about Python (67% relevant)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Q: "Python
                  syntax", Retrieved docs mostly about Java/C++ (20% relevant)
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- RAGAS SECTION -->
        <div class="framework-section">
          <h2 class="framework-title ragas-title">
            <span class="icon">🟣</span> RAGAS Framework
            <span class="badge-count">3 Metrics</span>
            <a
              href="https://docs.ragas.io/"
              target="_blank"
              class="framework-docs-link"
              >📖 Docs</a
            >
          </h2>
          <div class="framework-desc ragas-desc">
            <strong>RAGAS (Retrieval-Augmented Generation Assessment)</strong>
            is a specialized framework for evaluating RAG systems. Offers both
            non-LLM (fast) and LLM-based (accurate) metrics for comprehensive
            assessment.
          </div>

          <!-- RAGAS Metrics -->
          <div class="metrics-grid">
            <!-- BLEU Score -->
            <div class="metric-card ragas">
              <div class="metric-header">
                <div class="metric-name">BLEU Score</div>
                <span class="metric-tag tag-non-llm">Non-LLM</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> PROPORTION of n-gram matching between
                generated and expected output (no semantic understanding).
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = No overlap</span>
                  <span class="status status-partial"
                    >0.3-0.5 = Fair overlap</span
                  >
                  <span class="status status-pass"
                    >0.6-1.0 = Excellent overlap</span
                  >
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of n-grams matching)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li>
                    <strong>0.0:</strong> No n-gram overlap with reference
                  </li>
                  <li><strong>0.0-0.2:</strong> ≤20% n-grams match</li>
                  <li><strong>0.2-0.4:</strong> 20-40% n-grams match</li>
                  <li>
                    <strong>0.4-0.6:</strong> 40-60% n-grams match (significant
                    similarity)
                  </li>
                  <li>
                    <strong>0.6-1.0:</strong> ≥60% n-grams match (very similar)
                  </li>
                </ul>
              </div>

              <div class="section-title">Characteristics:</div>
              <div class="use-cases">
                <span class="feature-highlight">✓ Fast</span>
                <span class="feature-highlight">✓ No API calls</span>
                <span class="feature-highlight cons"
                  >✗ No semantic understanding</span
                >
                <span class="feature-highlight cons">✗ Less reliable</span>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Quick baseline testing, word-level matching, testing before LLM
                evaluation
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Expected:
                  "Paris is the capital", Generated: "Paris is the capital"
                  (100% match)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span>
                  Expected: "Paris is the capital", Generated: "Paris is
                  capital" (80% match)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Expected:
                  "Paris is the capital", Generated: "The capital is Paris" (low
                  n-gram overlap)
                </div>
              </div>
            </div>

            <!-- LLMContextRecall -->
            <div class="metric-card ragas">
              <div class="metric-header">
                <div class="metric-name">LLMContextRecall</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> PROPORTION of context information
                recalled/used in the response (semantic understanding).
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-fail">0.0 = No recall</span>
                  <span class="status status-partial">0.3-0.7 = Fair</span>
                  <span class="status status-pass">0.7-1.0 = Excellent</span>
                </div>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (PROPORTION of context recalled in
                  response)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li><strong>0.0:</strong> No context information recalled</li>
                  <li><strong>0.0-0.3:</strong> ≤30% of context recalled</li>
                  <li>
                    <strong>0.3-0.5:</strong> 30-50% of context recalled (fair)
                  </li>
                  <li>
                    <strong>0.5-0.7:</strong> 50-70% of context recalled (good)
                  </li>
                  <li>
                    <strong>0.7-1.0:</strong> ≥70% of context recalled
                    (excellent)
                  </li>
                </ul>
              </div>

              <div class="section-title">Characteristics:</div>
              <div class="use-cases">
                <span class="feature-highlight">✓ Semantic understanding</span>
                <span class="feature-highlight">✓ Production-ready</span>
                <span class="feature-highlight">✓ Accurate</span>
                <span class="feature-highlight cons"
                  >✗ Slower than non-LLM</span
                >
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Production RAG evaluation, context coverage assessment, quality
                assurance
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Context: "The
                  meeting is at 3 PM on Tuesday", Response mentions time and day
                  (100% recall)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span> Context
                  has 5 key points, response captures 3 (60% recall)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Context has
                  important details, response missing key facts (30% recall)
                </div>
              </div>
            </div>

            <!-- NoiseSensitivity -->
            <div class="metric-card ragas">
              <div class="metric-header">
                <div class="metric-name">NoiseSensitivity</div>
                <span class="metric-tag tag-llm">LLM-Based</span>
              </div>

              <div class="purpose">
                <strong>Purpose:</strong> LLM-based metric measuring response
                robustness to irrelevant/noisy context injection. Calculates
                proportion of incorrect claims when noise is added (0.0 = no
                errors, 1.0 = all errors).
              </div>

              <div class="threshold-section">
                <div class="threshold-simple">
                  <span class="status status-pass">0.0 = Perfect</span>
                  <span class="status status-partial">0.0-0.5 = Good</span>
                  <span class="status status-fail">0.5+ = Poor</span>
                </div>
              </div>

              <div class="section-title">Characteristics:</div>
              <div class="use-cases">
                <span class="feature-highlight">✓ Robustness testing</span>
                <span class="feature-highlight">✓ Semantic understanding</span>
                <span class="feature-highlight">✓ Production-ready</span>
                <span class="feature-highlight cons">✗ Slower evaluation</span>
              </div>

              <div class="section-title">Score Meaning:</div>
              <div class="use-cases">
                <strong
                  >Range: 0.0 to 1.0 (Proportion of incorrect claims when noise
                  added)</strong
                >
                <ul style="margin-top: 10px; padding-left: 20px">
                  <li>
                    <strong>0.0:</strong> Perfect robustness (all claims remain
                    correct despite noise)
                  </li>
                  <li>
                    <strong>0.0-0.3:</strong> Good robustness (≤30% of claims
                    become incorrect)
                  </li>
                  <li>
                    <strong>0.3-0.5:</strong> Fair robustness (30-50% of claims
                    become incorrect)
                  </li>
                  <li>
                    <strong>0.5+:</strong> Poor robustness (>50% of claims
                    become incorrect with noise)
                  </li>
                </ul>
              </div>

              <div class="section-title">Use Cases:</div>
              <div class="use-cases">
                Prompt injection vulnerability testing, RAG robustness
                evaluation, system resilience assessment, noise tolerance
                analysis
              </div>

              <div class="examples">
                <strong>Examples:</strong>
                <div class="example-item">
                  <span class="status status-pass">✅ PASS</span> Score 0.0 (all
                  claims correct despite noise - 0 errors out of total)
                </div>
                <div class="example-item">
                  <span class="status status-partial">⚠️ PARTIAL</span> Score
                  0.33 (some claims become incorrect with noise - 1 error out of
                  3 claims)
                </div>
                <div class="example-item">
                  <span class="status status-fail">❌ FAIL</span> Score 0.75
                  (many claims become incorrect with noise - 3 errors out of 4
                  claims)
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- COMPARISON TABLE -->
        <div class="framework-section">
          <h2 style="font-size: 1.8em; margin-bottom: 25px; color: #333">
            📊 Metrics Comparison Matrix
          </h2>
          <table class="comparison-table">
            <thead>
              <tr>
                <th>Metric</th>
                <th>Framework</th>
                <th>Type</th>
                <th>Score Meaning</th>
                <th>Primary Use</th>
                <th>Speed</th>
                <th>Accuracy</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>GEval</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.8=Excellent</td>
                <td>Custom criteria</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>Answer Relevancy</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.7=Highly relevant</td>
                <td>Q&A relevance</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>BiasMetric</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.0=No bias</td>
                <td>Bias detection</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>FaithfulnessMetric</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.7=Highly faithful</td>
                <td>Fact checking</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>Contextual Precision</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.7-1.0=Excellent</td>
                <td>RAG precision</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>Contextual Recall</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.7-1.0=Excellent</td>
                <td>RAG recall</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>Contextual Relevancy</strong></td>
                <td>DeepEval</td>
                <td>LLM-Based</td>
                <td>0.7-1.0=Excellent</td>
                <td>Retrieval quality</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>BLEU Score</strong></td>
                <td>RAGAS</td>
                <td>Non-LLM</td>
                <td>0.6-1.0=Excellent</td>
                <td>Baseline testing</td>
                <td>Fast</td>
                <td>Low</td>
              </tr>
              <tr>
                <td><strong>LLMContextRecall</strong></td>
                <td>RAGAS</td>
                <td>LLM-Based</td>
                <td>0.7-1.0=Excellent</td>
                <td>RAG evaluation</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
              <tr>
                <td><strong>NoiseSensitivity</strong></td>
                <td>RAGAS</td>
                <td>LLM-Based</td>
                <td>0.0=Perfect</td>
                <td>Response robustness</td>
                <td>Medium</td>
                <td>High</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <footer>
        <div class="footer-inner">
          <p style="font-size: 1.2em; font-weight: bold; margin-bottom: 10px">
            📚 LLM Evaluation Metrics Documentation
          </p>
          <p style="font-size: 0.9em; margin-bottom: 20px; opacity: 0.9">
            October 2025
          </p>

          <p style="font-size: 0.95em; margin-bottom: 15px">
            Credits:
            <a
              href="https://github.com/sritajkumarpatel/learn_llmtesting_2025"
              target="_blank"
              style="font-weight: bold"
            >
              learn_llmtesting_2025
            </a>
          </p>

          <p style="font-size: 0.9em; margin-bottom: 15px">
            Based on <strong>DeepEval</strong> &
            <strong>RAGAS</strong> frameworks •
            <a href="https://deepeval.com/docs/getting-started" target="_blank">
              DeepEval Docs
            </a>
            •
            <a href="https://docs.ragas.io/" target="_blank"> RAGAS Docs </a>
          </p>

          <p style="font-size: 0.85em; opacity: 0.85">
            © 2025 Sri Taj Kumar Patel | Educational reference for LLM
            evaluation metrics
          </p>
        </div>
      </footer>
    </div>
  </body>
</html>
